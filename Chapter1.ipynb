{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1286a1d",
      "metadata": {
        "id": "f1286a1d"
      },
      "source": [
        "## Chaper 1: Pay Attention to LLMs\n",
        "\n",
        "### Spoilers\n",
        "\n",
        "In this chapter, we’ll:\n",
        "\n",
        "- Briefly discuss the history of language models\n",
        "- Understand the basic elements of the Transformer architecture and the attention mechanism\n",
        "- Understand the different types of fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15dd32eb",
      "metadata": {
        "id": "15dd32eb"
      },
      "source": [
        "### Transformers\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch1/stacked_layers.png?raw=True)\n",
        "<center>Figure 1.1 - Transformer’s stacked \"layers\"</center>\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch1/full_transformer.png?raw=True)\n",
        "<center>Figure 1.2 - Transformer architecture in detail</center>\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch1/bert_embeddings.png?raw=True)\n",
        "<center>Figure 1.3 - Contextual word embeddings from BERT</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c552996",
      "metadata": {
        "id": "3c552996"
      },
      "source": [
        "### Attention Is All You Need\n",
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
        "$$\n",
        "<center>Equation 1.1 - Attention formula</center>\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch1/translation_att.png?raw=True)\n",
        "<center>Figure 1.4 - Attention scores</center>\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch1/multiple_keys_context.png?raw=True)\n",
        "<center>Figure 1.5 - Querying two-dimensional keys</center>\n",
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{cos}\\theta = ||Q|| ||K|| = Q \\cdot K\n",
        "$$\n",
        "<center>Equation 1.2 - Cosine similarity, norms, and the dot product</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b9fb7348",
      "metadata": {
        "id": "b9fb7348"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer\n",
        "repo_id = 'microsoft/Phi-3-mini-4k-instruct'\n",
        "tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
        "vocab_size = len(tokenizer)\n",
        "\n",
        "torch.manual_seed(13)\n",
        "# Made-up embedding and projection layers\n",
        "d_model = 1024\n",
        "embedding_layer = nn.Embedding(vocab_size, d_model)\n",
        "linear_query = nn.Linear(d_model, d_model)\n",
        "linear_key = nn.Linear(d_model, d_model)\n",
        "linear_value = nn.Linear(d_model, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "af735141",
      "metadata": {
        "id": "af735141",
        "outputId": "4e446e5b-b461-4242-f65b-d4040ad66140",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3387,   263, 20254, 10541]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "sentence = 'Just a dummy sentence'\n",
        "input_ids = tokenizer(sentence, return_tensors='pt')['input_ids']\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b190fc58",
      "metadata": {
        "id": "b190fc58",
        "outputId": "2b437376-f5df-4a42-e9a4-3196a34d7b79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "embeddings = embedding_layer(input_ids)\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "794a0b59",
      "metadata": {
        "id": "794a0b59",
        "outputId": "f84c9d5f-73af-459d-c1ee-b07977a9e825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Projections\n",
        "proj_key = linear_key(embeddings)\n",
        "proj_value = linear_value(embeddings)\n",
        "proj_query = linear_query(embeddings)\n",
        "# Attention scores\n",
        "dot_products = torch.matmul(proj_query, proj_key.transpose(-2, -1))\n",
        "scores = F.softmax(dot_products / np.sqrt(d_model), dim=-1)\n",
        "scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0269fc68",
      "metadata": {
        "id": "0269fc68",
        "outputId": "3c711a12-427b-4073-ce00-5b3adbef3db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "context = torch.matmul(scores, proj_value)\n",
        "context.shape"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}